## 4.3 Performance Optimization

### Learning Objectives
By the end of this section, students will be able to:
- Implement effective caching strategies
- Configure compression for API responses
- Design efficient batch operations
- Set up comprehensive performance monitoring
- Optimize database queries and connections

### 1. Caching Strategies

#### 1.1 HTTP Caching
```javascript
// Express.js caching middleware
const setCacheHeaders = (duration) => {
    return (req, res, next) => {
        // Don't cache if authenticated
        if (req.user) {
            res.setHeader('Cache-Control', 'private, no-cache');
            return next();
        }

        res.setHeader('Cache-Control', `public, max-age=${duration}`);
        res.setHeader('Expires', new Date(Date.now() + duration * 1000).toUTCString());
        next();
    };
};

// Usage for different endpoints
app.get('/api/products', setCacheHeaders(3600), getProducts); // Cache for 1 hour
app.get('/api/news', setCacheHeaders(300), getNews);     // Cache for 5 minutes
```

#### 1.2 Redis Caching
```javascript
const Redis = require('ioredis');
const redis = new Redis({
    host: 'localhost',
    port: 6379,
    maxRetriesPerRequest: 3,
    retryStrategy: (times) => Math.min(times * 50, 2000)
});

// Caching middleware with Redis
const cacheMiddleware = (keyPrefix, duration) => {
    return async (req, res, next) => {
        const key = `${keyPrefix}:${req.originalUrl}`;
        
        try {
            const cachedResponse = await redis.get(key);
            
            if (cachedResponse) {
                return res.json(JSON.parse(cachedResponse));
            }
            
            // Store original send method
            const originalSend = res.json;
            
            // Override res.json method
            res.json = function (body) {
                redis.setex(key, duration, JSON.stringify(body))
                    .catch(err => console.error('Cache storage error:', err));
                    
                return originalSend.call(this, body);
            };
            
            next();
        } catch (err) {
            console.error('Cache error:', err);
            next();
        }
    };
};

// Implementation example
app.get('/api/products', 
    cacheMiddleware('products', 3600),
    async (req, res) => {
        const products = await Product.find();
        res.json(products);
    }
);
```

#### 1.3 Cache Invalidation Strategies
```javascript
// Cache invalidation middleware
const invalidateCache = (patterns) => {
    return async (req, res, next) => {
        const originalSend = res.json;
        
        res.json = async function (body) {
            try {
                // Get all keys matching patterns
                for (const pattern of patterns) {
                    const keys = await redis.keys(pattern);
                    if (keys.length > 0) {
                        await redis.del(...keys);
                    }
                }
            } catch (err) {
                console.error('Cache invalidation error:', err);
            }
            
            return originalSend.call(this, body);
        };
        
        next();
    };
};

// Usage example
app.post('/api/products',
    invalidateCache(['products:*', 'categories:*']),
    createProduct
);
```

### 2. Compression

#### 2.1 Response Compression
```javascript
const compression = require('compression');

// Basic compression
app.use(compression());

// Advanced compression configuration
app.use(compression({
    // Compression level (0-9)
    level: 6,
    
    // Only compress responses larger than 1KB
    threshold: 1024,
    
    // Compress only specific content types
    filter: (req, res) => {
        if (req.headers['x-no-compression']) {
            return false;
        }
        
        return compression.filter(req, res);
    },
    
    // Custom compression options
    chunkSize: 16384,
    memLevel: 8
}));

// Brotli compression (more efficient than gzip)
const shrinkRay = require('shrink-ray-current');
app.use(shrinkRay());
```

### 3. Batch Operations

#### 3.1 Bulk Database Operations
```javascript
// MongoDB bulk operations
const bulkUpsertProducts = async (products) => {
    const operations = products.map(product => ({
        updateOne: {
            filter: { _id: product._id },
            update: { $set: product },
            upsert: true
        }
    }));

    const bulkOp = Product.collection.bulkWrite(operations, {
        ordered: false // Allow parallel processing
    });

    return bulkOp;
};

// Batch API endpoint
app.post('/api/products/batch', async (req, res) => {
    const { products } = req.body;
    
    if (!Array.isArray(products)) {
        return res.status(400).json({ error: 'Products must be an array' });
    }
    
    // Limit batch size
    if (products.length > 1000) {
        return res.status(400).json({ error: 'Batch size too large' });
    }
    
    try {
        const result = await bulkUpsertProducts(products);
        res.json(result);
    } catch (err) {
        res.status(500).json({ error: err.message });
    }
});
```

#### 3.2 Parallel Processing
```javascript
// Parallel processing with Promise.all
const processBatchParallel = async (items, batchSize = 100) => {
    const batches = [];
    
    for (let i = 0; i < items.length; i += batchSize) {
        batches.push(items.slice(i, i + batchSize));
    }
    
    const results = await Promise.all(
        batches.map(batch => processBatch(batch))
    );
    
    return results.flat();
};

// Rate-limited parallel processing
const pLimit = require('p-limit');

const processWithRateLimit = async (items, concurrency = 5) => {
    const limit = pLimit(concurrency);
    
    const promises = items.map(item => 
        limit(() => processItem(item))
    );
    
    return Promise.all(promises);
};
```

### 4. Performance Monitoring

#### 4.1 Response Time Monitoring
```javascript
// Response time middleware
const responseTime = (req, res, next) => {
    const start = process.hrtime();
    
    res.on('finish', () => {
        const [seconds, nanoseconds] = process.hrtime(start);
        const duration = seconds * 1000 + nanoseconds / 1e6; // Convert to milliseconds
        
        // Log or store metrics
        logMetrics({
            path: req.path,
            method: req.method,
            statusCode: res.statusCode,
            duration,
            timestamp: new Date()
        });
    });
    
    next();
};
```

#### 4.2 Prometheus Metrics
```javascript
const prometheus = require('prom-client');

// Create metrics
const httpRequestDuration = new prometheus.Histogram({
    name: 'http_request_duration_seconds',
    help: 'Duration of HTTP requests in seconds',
    labelNames: ['method', 'route', 'status_code'],
    buckets: [0.1, 0.5, 1, 2, 5]
});

const httpRequestTotal = new prometheus.Counter({
    name: 'http_requests_total',
    help: 'Total number of HTTP requests',
    labelNames: ['method', 'route', 'status_code']
});

// Metrics middleware
app.use((req, res, next) => {
    const end = httpRequestDuration.startTimer();
    
    res.on('finish', () => {
        end({
            method: req.method,
            route: req.route?.path || req.path,
            status_code: res.statusCode
        });
        
        httpRequestTotal.inc({
            method: req.method,
            route: req.route?.path || req.path,
            status_code: res.statusCode
        });
    });
    
    next();
});

// Metrics endpoint
app.get('/metrics', async (req, res) => {
    res.set('Content-Type', prometheus.register.contentType);
    res.end(await prometheus.register.metrics());
});
```

#### 4.3 Performance Testing
```javascript
// Load testing with Artillery
// artillery.yml
const config = {
    target: 'http://api.example.com',
    phases: [
        { duration: 60, arrivalRate: 5 },  // Warm up
        { duration: 120, arrivalRate: 10 }, // Ramp up
        { duration: 300, arrivalRate: 30 }, // Sustained load
        { duration: 60, arrivalRate: 0 }   // Cool down
    ],
    defaults: {
        headers: {
            'Content-Type': 'application/json'
        }
    },
    scenarios: [
        {
            name: 'API endpoints',
            flow: [
                { get: { url: '/api/products' } },
                { think: 2 },
                { get: { url: '/api/categories' } },
                { think: 1 },
                {
                    post: {
                        url: '/api/orders',
                        json: {
                            productId: '{{$randomString()}}',
                            quantity: '{{$randomNumber(1, 5)}}'
                        }
                    }
                }
            ]
        }
    ]
};
```

### 5. Database Optimization

#### 5.1 Query Optimization
```javascript
// MongoDB index creation
db.products.createIndex({ name: 1, category: 1 });
db.orders.createIndex({ userId: 1, createdAt: -1 });

// Efficient querying
const getProducts = async (filters) => {
    return Product.find(filters)
        .select('name price category') // Select only needed fields
        .lean()                        // Return plain objects
        .hint({ name: 1, category: 1 }) // Use specific index
        .limit(100);
};

// Aggregation pipeline optimization
const getOrderStats = async (userId) => {
    return Order.aggregate([
        { $match: { userId } },        // Early filtering
        { $sort: { createdAt: -1 } }, // Use index
        {
            $group: {
                _id: '$status',
                count: { $sum: 1 },
                total: { $sum: '$amount' }
            }
        }
    ]).allowDiskUse(true);
};
```

#### 5.2 Connection Pool Management
```javascript
// MongoDB connection pool
mongoose.connect(MONGODB_URI, {
    maxPoolSize: 100,
    minPoolSize: 10,
    maxIdleTimeMS: 30000,
    waitQueueTimeoutMS: 10000,
    waitQueueMultiple: 10
});

// PostgreSQL pool configuration
const { Pool } = require('pg');
const pool = new Pool({
    max: 20,              // Maximum number of clients
    idleTimeoutMillis: 30000,
    connectionTimeoutMillis: 2000,
    maxUses: 7500        // Number of queries before client release
});
```

### Practice Exercises

1. Implement a multi-level caching strategy (Browser → CDN → API → Database)
2. Create a batch processing system with progress tracking
3. Set up a comprehensive monitoring dashboard
4. Optimize database queries and measure performance improvements

### Performance Checklist
- [ ] Implement appropriate caching strategies
- [ ] Configure response compression
- [ ] Set up batch processing for bulk operations
- [ ] Implement performance monitoring
- [ ] Optimize database queries and indexes
- [ ] Configure connection pooling
- [ ] Set up load testing
- [ ] Implement rate limiting
- [ ] Use CDN for static assets
- [ ] Configure horizontal scaling

### Additional Resources
- [Node.js Performance Guide](https://nodejs.org/en/docs/guides/diagnostics/memory-leaks)
- [MongoDB Performance Best Practices](https://www.mongodb.com/docs/manual/core/query-optimization/)
- [Redis Caching Patterns](https://redis.io/docs/manual/patterns/)
- [Artillery Load Testing](https://www.artillery.io/docs)
